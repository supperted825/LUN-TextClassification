{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cls                                               text\n",
       "0    1  A little less than a decade ago, hockey fans w...\n",
       "1    1  The writers of the HBO series The Sopranos too...\n",
       "2    1  Despite claims from the TV news outlet to offe...\n",
       "3    1  After receiving 'subpar' service and experienc...\n",
       "4    1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./raw_data/fulltrain.csv', header=None)\n",
    "data.columns = ['cls', 'text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propaganda    17870\n",
       "satire        14047\n",
       "reliable       9995\n",
       "hoax           6942\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_names = { 0 : \"satire\", 1 : \"hoax\", 2 : \"propaganda\", 3 : \"reliable\"}\n",
    "data['cls'] = data['cls'] - 1\n",
    "data['cls'].map(cls_names).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satire        750\n",
       "hoax          750\n",
       "propaganda    750\n",
       "reliable      750\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./raw_data/balancedtest.csv', header=None)\n",
    "test_data.columns = ['cls', 'text']\n",
    "test_data['cls'] = test_data['cls'] - 1\n",
    "test_data['cls'].map(cls_names).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1506\n",
       "3      41\n",
       "0      14\n",
       "1       8\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_tokens'] = data['text'].apply(lambda x: len(wordpunct_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1506\n",
       "3      41\n",
       "0      14\n",
       "1       8\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['num_tokens'] < 10]['cls'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['num_tokens'] = test_data['text'].apply(lambda x: len(wordpunct_tokenize(x)))\n",
    "test_data[test_data['num_tokens'] < 10]['cls'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Gram Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class satire\n",
      "Top by Count [('one', 11426), ('time', 11092), ('would', 9736), ('like', 9278), ('new', 7558), ('year', 7120), ('even', 6508), ('added', 6302), ('get', 6298), ('could', 6163), ('people', 5741), ('amp', 5241), ('amp amp', 5196), ('first', 5175), ('also', 5140), ('old', 5132), ('monday', 5079), ('day', 4879), ('really', 4872), ('years', 4834)]\n",
      "Top by TFIDF ['finally', 'say', 'people', 'thats', 'lead', 'hit', 'else', 'fans', 'wanted', 'coming', '30', 'behind', 'top', 'however', 'pretty', 'went', 'might', 'away', 'us', 'something']\n",
      "Class hoax\n",
      "Top by Count [('obama', 7069), ('think', 6185), ('trump', 4915), ('one', 3612), ('president', 3583), ('according', 3194), ('video', 3052), ('people', 2878), ('would', 2770), ('reports', 2768), ('time', 2583), ('told', 2311), ('country', 2214), ('clinton', 2181), ('also', 2178), ('like', 2171), ('american', 2148), ('recent', 2128), ('new', 2127), ('us', 2114)]\n",
      "Top by TFIDF ['white', 'black', 'people', 'president', 'say', 'racist', 'local', 'leave', 'others', 'message', 'although', 'matter', 'reported', 'concluded', 'wrote', 'received', 'actions', 'clear', 'given', 'claiming']\n",
      "Class propaganda\n",
      "Top by Count [('us', 42476), ('people', 42190), ('one', 39459), ('would', 39135), ('government', 36589), ('like', 28146), ('also', 25139), ('new', 24965), ('even', 24487), ('world', 23964), ('time', 23596), ('many', 21770), ('state', 20577), ('said', 19530), ('could', 19254), ('states', 18162), ('years', 18142), ('well', 17724), ('first', 17443), ('get', 17275)]\n",
      "Top by TFIDF ['forces', 'syria', 'us', 'syrian', 'another', 'russia', 'stated', 'including', 'nation', 'reported', 'author', 'com', 'military', 'nato', 'part', 'terrorists', 'youre', 'every', 'air', 'western']\n",
      "Class reliable\n",
      "Top by Count [('said', 38621), ('year', 10367), ('would', 10266), ('one', 9925), ('percent', 9356), ('new', 8952), ('also', 8230), ('two', 8114), ('people', 8025), ('taiwan', 7324), ('government', 7010), ('first', 6502), ('last', 6047), ('time', 5966), ('years', 5801), ('president', 5787), ('china', 5733), ('could', 5299), ('like', 4889), ('million', 4785)]\n",
      "Top by TFIDF ['nt', 'tax', 'billion', 'ministry', 'million', 'seven', 'total', '50', 'saturday', 'administration', 'big', 'company', '15', 'least', 'official', 'days', 'top', 'friday', 'around', 'public']\n"
     ]
    }
   ],
   "source": [
    "top_keywords = {}\n",
    "top_counts = {}\n",
    "\n",
    "for y, name in cls_names.items():\n",
    "    \n",
    "    cls_docs = data[data.cls == y]['text'].tolist()\n",
    "    \n",
    "    cvect = CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=stopwords.words('english'),\n",
    "        max_df=0.8,\n",
    "        min_df=10,\n",
    "        max_features=500\n",
    "    )\n",
    "    \n",
    "    tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=stopwords.words('english'),\n",
    "        max_df=0.8,\n",
    "        min_df=10,\n",
    "        max_features=500\n",
    "    )\n",
    "    \n",
    "    tfidf_vect = tfidf.fit_transform(cls_docs)\n",
    "    feature_array = np.array(tfidf.get_feature_names_out())\n",
    "    tfidf_sorting = np.argsort(tfidf_vect.toarray()).flatten()[::-1]\n",
    "    top_n = feature_array[tfidf_sorting].tolist()\n",
    "    \n",
    "    sum_words = cvect.fit_transform(cls_docs).sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cvect.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print('Class', name)\n",
    "    print('Top by Count', words_freq[:20])\n",
    "    print('Top by TFIDF', top_n[:20])\n",
    "    \n",
    "    top_keywords[name] = top_n[:500]\n",
    "    top_counts[name] = words_freq[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection between satire & hoax: 306\n",
      "Intersection between satire & propaganda: 295\n",
      "Intersection between satire & reliable: 314\n",
      "Intersection between hoax & satire: 306\n",
      "Intersection between hoax & propaganda: 296\n",
      "Intersection between hoax & reliable: 269\n",
      "Intersection between propaganda & satire: 295\n",
      "Intersection between propaganda & hoax: 296\n",
      "Intersection between propaganda & reliable: 312\n",
      "Intersection between reliable & satire: 314\n",
      "Intersection between reliable & hoax: 269\n",
      "Intersection between reliable & propaganda: 312\n"
     ]
    }
   ],
   "source": [
    "for cls1 in cls_names.values():\n",
    "    for cls2 in cls_names.values():\n",
    "        if cls1 == cls2:\n",
    "            continue\n",
    "        print(f'Intersection between {cls1} & {cls2}:', len(set(top_keywords[cls1]).intersection(top_keywords[cls2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection between satire & hoax: 306\n",
      "[('one', 11426, 3612), ('time', 11092, 2583), ('would', 9736, 2770), ('like', 9278, 2171), ('new', 7558, 2127), ('year', 7120, 1717), ('even', 6508, 1318), ('get', 6298, 1422), ('could', 6163, 1458), ('people', 5741, 2878)]\n",
      "Intersection between satire & propaganda: 295\n",
      "[('one', 11426, 39459), ('time', 11092, 23596), ('would', 9736, 39135), ('like', 9278, 28146), ('new', 7558, 24965), ('year', 7120, 13522), ('even', 6508, 24487), ('get', 6298, 17275), ('could', 6163, 19254), ('people', 5741, 42190)]\n",
      "Intersection between satire & reliable: 314\n",
      "[('one', 11426, 9925), ('time', 11092, 5966), ('would', 9736, 10266), ('like', 9278, 4889), ('new', 7558, 8952), ('year', 7120, 10367), ('even', 6508, 3619), ('added', 6302, 2215), ('get', 6298, 3473), ('could', 6163, 5299)]\n",
      "Intersection between hoax & satire: 306\n",
      "[('obama', 7069, 1583), ('think', 6185, 3378), ('one', 3612, 11426), ('president', 3583, 3915), ('according', 3194, 4366), ('people', 2878, 5741), ('would', 2770, 9736), ('reports', 2768, 993), ('time', 2583, 11092), ('told', 2311, 4365)]\n",
      "Intersection between hoax & propaganda: 296\n",
      "[('obama', 7069, 9348), ('think', 6185, 12371), ('one', 3612, 39459), ('president', 3583, 7992), ('according', 3194, 10569), ('video', 3052, 4911), ('people', 2878, 42190), ('would', 2770, 39135), ('reports', 2768, 5139), ('time', 2583, 23596)]\n",
      "Intersection between hoax & reliable: 269\n",
      "[('obama', 7069, 3277), ('think', 6185, 2113), ('one', 3612, 9925), ('president', 3583, 5787), ('according', 3194, 3916), ('people', 2878, 8025), ('would', 2770, 10266), ('time', 2583, 5966), ('told', 2311, 3250), ('country', 2214, 4033)]\n",
      "Intersection between propaganda & satire: 295\n",
      "[('us', 42476, 3089), ('people', 42190, 5741), ('one', 39459, 11426), ('would', 39135, 9736), ('government', 36589, 1177), ('like', 28146, 9278), ('also', 25139, 5140), ('new', 24965, 7558), ('even', 24487, 6508), ('world', 23964, 3258)]\n",
      "Intersection between propaganda & hoax: 296\n",
      "[('us', 42476, 2114), ('people', 42190, 2878), ('one', 39459, 3612), ('would', 39135, 2770), ('government', 36589, 958), ('like', 28146, 2171), ('also', 25139, 2178), ('new', 24965, 2127), ('even', 24487, 1318), ('world', 23964, 903)]\n",
      "Intersection between propaganda & reliable: 312\n",
      "[('us', 42476, 4278), ('people', 42190, 8025), ('one', 39459, 9925), ('would', 39135, 10266), ('government', 36589, 7010), ('like', 28146, 4889), ('also', 25139, 8230), ('new', 24965, 8952), ('even', 24487, 3619), ('world', 23964, 4739)]\n",
      "Intersection between reliable & satire: 314\n",
      "[('year', 10367, 7120), ('would', 10266, 9736), ('one', 9925, 11426), ('percent', 9356, 2146), ('new', 8952, 7558), ('also', 8230, 5140), ('two', 8114, 4715), ('people', 8025, 5741), ('government', 7010, 1177), ('first', 6502, 5175)]\n",
      "Intersection between reliable & hoax: 269\n",
      "[('said', 38621, 2113), ('year', 10367, 1717), ('would', 10266, 2770), ('one', 9925, 3612), ('new', 8952, 2127), ('also', 8230, 2178), ('two', 8114, 1450), ('people', 8025, 2878), ('government', 7010, 958), ('first', 6502, 1811)]\n",
      "Intersection between reliable & propaganda: 312\n",
      "[('said', 38621, 19530), ('year', 10367, 13522), ('would', 10266, 39135), ('one', 9925, 39459), ('percent', 9356, 6371), ('new', 8952, 24965), ('also', 8230, 25139), ('two', 8114, 12057), ('people', 8025, 42190), ('government', 7010, 36589)]\n"
     ]
    }
   ],
   "source": [
    "for cls1 in cls_names.values():\n",
    "    for cls2 in cls_names.values():\n",
    "        \n",
    "        if cls1 == cls2:\n",
    "            continue\n",
    "        \n",
    "        cls1_words = [w for w, c in top_counts[cls1]]\n",
    "        cls2_words = [w for w, c in top_counts[cls2]]\n",
    "        cls1_count_dict = dict(top_counts[cls1])\n",
    "        cls2_count_dict = dict(top_counts[cls2])\n",
    "        \n",
    "        intersect_words = set(cls1_words).intersection(cls2_words)\n",
    "        print(f'Intersection between {cls1} & {cls2}:', len(intersect_words))\n",
    "        \n",
    "        top_intersecting_words = [(w, cls1_count_dict[w], cls2_count_dict[w]) for w in intersect_words]\n",
    "        \n",
    "        print(sorted(top_intersecting_words, key=lambda x: (x[1], x[2]), reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
